{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img, img_to_array, array_to_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5820\\4237952478.py:34: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  image = image.resize(desired_size, Image.ANTIALIAS)  # Resize using antialiasing for better quality\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Define the path to the source folder containing your images\n",
    "source_folder = r'C:\\Users\\user\\Desktop\\cv models\\bottle\\train\\good'\n",
    "\n",
    "# Define the path to the destination folder where resized images will be saved\n",
    "destination_folder = r'C:\\Users\\user\\Desktop\\cv models\\bottle\\train\\generated_resized'\n",
    "\n",
    "# Ensure the destination folder exists; create it if it doesn't\n",
    "image_files = [f for f in os.listdir(source_folder) if f.endswith(('jpg', 'jpeg', 'png'))]\n",
    "\n",
    "def generator(image_files):\n",
    "    datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,  # Rescale pixel values to [0, 1]\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True\n",
    "    )\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # List image files in the source folder\n",
    "   \n",
    "\n",
    "    # Set the desired width and height for resizing\n",
    "    width = height = 256\n",
    "    desired_size = (width, height)  # Replace 'width' and 'height' with your desired dimensions\n",
    "\n",
    "    # Loop through the image files, resize, and save them in the destination folder\n",
    "    i = 0\n",
    "    for image_file in image_files:\n",
    "        source_path = os.path.join(source_folder, image_file)\n",
    "        image = Image.open(source_path)\n",
    "        image = image.resize(desired_size, Image.ANTIALIAS)  # Resize using antialiasing for better quality\n",
    "        \n",
    "        # Save the resized image in the destination folder\n",
    "        image_array = img_to_array(image)\n",
    "\n",
    "        # Reshape for batch processing (batch size = 1)\n",
    "        image_array = image_array.reshape((1,) + image_array.shape)\n",
    "\n",
    "        \n",
    "        for batch in datagen.flow(image_array, batch_size=1):\n",
    "            augmented_image = batch[0]  # Extract the augmented image\n",
    "            augmented_image_path = os.path.join(destination_folder, f'augmented_{i}.jpg')\n",
    "            \n",
    "            # Convert the augmented image back to a valid image format and save it\n",
    "            augmented_image = (augmented_image * 255).astype('uint8')  # Convert back to uint8 format\n",
    "            augmented_image = array_to_img(augmented_image)  # Convert to PIL Image\n",
    "            augmented_image.save(augmented_image_path)\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "            if i >= 1000:\n",
    "                break\n",
    "\n",
    "        # destination_path = os.path.join(destination_folder, 'resized_' + image_file)  # You can change the naming convention\n",
    "        # image.save(destination_path)\n",
    "\n",
    "generator(image_files)\n",
    "\n",
    "# print(\"Resized images have been saved in the destination folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Mask vgg16 to extract Features\n",
    "# !pip install torch torchvision Pillow numpy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\user/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [00:36<00:00, 15.1MB/s] \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "\n",
    "# Load the pre-trained VGG16 model\n",
    "vgg16 = models.vgg16(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Features from the images\n",
    "import os\n",
    "\n",
    "# Path to the folder containing training images\n",
    "training_data_folder = r\"C:\\Users\\user\\Desktop\\cv models\\bottle\\train\\generated_resized\"\n",
    "\n",
    "# Path to the folder where you want to save extracted features\n",
    "features_output_folder = r\"C:\\Users\\user\\Desktop\\cv models\\bottle\\output\"\n",
    "\n",
    "# Create the features output folder if it doesn't exist\n",
    "os.makedirs(features_output_folder, exist_ok=True)\n",
    "\n",
    "# Transformation to preprocess images\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                     std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "# Iterate through the images in the folder\n",
    "for filename in os.listdir(training_data_folder):\n",
    "    # if filename.endswith((\".jpg\", \".jpeg\", \".png\")):\n",
    "    image_path = os.path.join(training_data_folder, filename)\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image)\n",
    "    image = Variable(image.unsqueeze(0))  # Add a batch dimension\n",
    "\n",
    "    # Extract features using VGG16\n",
    "    features = vgg16(image)\n",
    "    features = features.squeeze().detach().numpy()\n",
    "\n",
    "    # Save the features to a file (you may want to serialize them)\n",
    "    feature_output_path = os.path.join(features_output_folder, f\"{os.path.splitext(filename)[0]}.npy\")\n",
    "    np.save(feature_output_path, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load extracted features\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "features_folder = r\"C:\\Users\\user\\Desktop\\cv models\\bottle\\output\"\n",
    "feature_files = [os.path.join(features_folder, file) for file in os.listdir(features_folder)]\n",
    "\n",
    "features = []\n",
    "for file in feature_files:\n",
    "    if file.endswith(\".npy\"):\n",
    "        feature = np.load(file)\n",
    "        features.append(feature)\n",
    "\n",
    "features = np.array(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1208"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a list of labels where 0 indicates seen classes and 1 indicates unseen classes\n",
    "# labels = [1] * 1208 + [1] * 4\n",
    "labels = [1] * 1008  + [4] * 200\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8099173553719008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a logistic regression classifier (replace with your preferred classifier)\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the classifier on the test set\n",
    "accuracy = classifier.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train a logistic regression classifier (replace with your preferred classifier)\n",
    "# classifier = LogisticRegression()\n",
    "# classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the classifier on the test set\n",
    "# accuracy = classifier.score(X_test, y_test)\n",
    "# print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labels)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
